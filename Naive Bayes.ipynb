{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "trainingSet = pd.read_csv(\"./data/X_train.csv\")\n",
    "submissionSet = pd.read_csv(\"./data/X_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(trainingSet,submissionSet,col = 'Text'):\n",
    "    training_helpful = trainingSet[(trainingSet['HelpfulnessNumerator']<=trainingSet['HelpfulnessDenominator'])]\n",
    "    training_drop = training_helpful.dropna()\n",
    "    print(\"train set after cleaning wrong in helpfulness:   \" , trainingSet.shape)\n",
    "    print(\"train set after drop NaN:   \",training_drop.shape)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        training_drop.drop(['Score'], axis=1),\n",
    "        training_drop['Score'],\n",
    "        test_size=1/4.0,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "\n",
    "    if col == 'Text':\n",
    "        drop_col = ['Id', 'ProductId', 'UserId', 'Summary', 'Time']\n",
    "    elif col == 'Summary':\n",
    "        drop_col = ['Id', 'ProductId', 'UserId', 'Text', 'Time']\n",
    "\n",
    "    X_train_processed = X_train.drop(columns = drop_col)\n",
    "    X_test_processed = X_test.drop(columns = drop_col)\n",
    "    submission_processed = submissionSet.drop(columns = drop_col)\n",
    "    print(\"train set shape:  \",X_train_processed.shape,\"test set shape:  \",X_test_processed.shape)\n",
    "    \n",
    "    return X_train_processed,X_test_processed,Y_train,Y_test,submission_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the text\n",
    "#https://stackoverflow.com/questions/5843518/remove-all-special-characters-punctuation-and-spaces-from-string\n",
    "#https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "def remove_char(x):\n",
    "    special = '[^A-Za-z0-9 ]+'\n",
    "    x = re.sub(special,'',x)\n",
    "    x = x.strip()\n",
    "    x = x.lower()\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_word(dataset,col):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    test = dataset[col].apply(lambda row: remove_char(str(row))).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming test\n",
    "#https://stackoverflow.com/questions/37443138/python-stemming-with-pandas-dataframe\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def stem(df):\n",
    "    df = df.str.split()\n",
    "    df = df.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    df = df.apply(lambda x: ','.join(map(str, x)))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set after cleaning wrong in helpfulness:    (1397533, 10)\n",
      "train set after drop NaN:    (1397455, 10)\n",
      "train set shape:   (1048091, 4) test set shape:   (349364, 4)\n"
     ]
    }
   ],
   "source": [
    "#SEPERATE THE DATASET text\n",
    "X_train_text,X_test_text,Y_train,Y_test,submission_text = process(trainingSet,submissionSet,'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214099    big fan miami vice enjoyed movie mainly enjoy ...\n",
       "544327    intimate fascinating biographic documentary gr...\n",
       "500542    movie really great way movie designed looked l...\n",
       "493726    tried watching tv missed several episodes enjo...\n",
       "579893    ok last movies shelf would reccomend someone t...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the text \n",
    "X_train_text = clean_word(X_train_text,'Text')\n",
    "X_test_text = clean_word(X_test_text,'Text')\n",
    "submission_text = clean_word(submission_text,'Text')\n",
    "X_train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214099    big,fan,miami,vice,enjoy,movi,main,enjoy,style...\n",
       "544327    intim,fascin,biograph,documentari,great,ballet...\n",
       "500542    movi,realli,great,way,movi,design,look,like,se...\n",
       "493726    tri,watch,tv,miss,sever,episod,enjoy,abl,watch...\n",
       "579893    ok,last,movi,shelf,would,reccomend,someon,type...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply stem to text\n",
    "X_train_text_stem = stem(X_train_text)\n",
    "X_test_text_stem = stem(X_test_text)\n",
    "X_submission_text_stem = stem(submission_text)\n",
    "X_train_text_stem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set after cleaning wrong in helpfulness:    (1397533, 10)\n",
      "train set after drop NaN:    (1397455, 10)\n",
      "train set shape:   (1048091, 4) test set shape:   (349364, 4)\n"
     ]
    }
   ],
   "source": [
    "#SEPERATE THE DATASET summary\n",
    "X_train_Summary,X_test_Summary,Y_train,Y_test,submission_Summary = process(trainingSet,submissionSet,'Summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214099                 miami vice meets silence lambs\n",
       "544327    intimate fascinating biographic documentary\n",
       "500542                                          great\n",
       "493726                                    24 season 1\n",
       "579893                                       response\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the summary\n",
    "X_train_Summary = clean_word(X_train_Summary,'Summary')\n",
    "X_test_Summary = clean_word(X_test_Summary,'Summary')\n",
    "submission_Summary = clean_word(submission_Summary,'Summary')\n",
    "X_train_Summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214099          miami,vice,meet,silenc,lamb\n",
       "544327    intim,fascin,biograph,documentari\n",
       "500542                                great\n",
       "493726                          24,season,1\n",
       "579893                              respons\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply stem to summary\n",
    "X_train_Summary_stem = stem(X_train_Summary)\n",
    "X_test_Summary_stem = stem(X_test_Summary)\n",
    "X_submission_Summary_stem = stem(submission_Summary)\n",
    "X_train_Summary_stem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of text train set: (1048091,)\n",
      "shape of text train stem set: (1048091,)\n",
      "shape of summary train set: (1048091,)\n",
      "shape of summary train stem set: (1048091,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of text train set:\",X_train_text.shape)\n",
    "print(\"shape of text train stem set:\",X_train_text_stem.shape)\n",
    "print(\"shape of summary train set:\",X_train_Summary.shape)\n",
    "print(\"shape of summary train stem set:\",X_train_Summary_stem.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTORIZING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countVector text\n",
    "text_vectorizer = CountVectorizer()\n",
    "X_train_text_vector = text_vectorizer.fit_transform(X_train_text)\n",
    "X_test_text_vector = text_vectorizer.transform(X_test_text)\n",
    "submission_text_vector = text_vectorizer.transform(submission_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf text\n",
    "text_tfidf = TfidfVectorizer()\n",
    "X_train_text_tfidf = text_tfidf.fit_transform(X_train_text)\n",
    "X_test_text_tfidf = text_tfidf.transform(X_test_text)\n",
    "submission_text_tfidf = text_tfidf.transform(submission_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countVector text stem\n",
    "text_stem_vectorizer = CountVectorizer()\n",
    "X_train_text_stem_vector = text_stem_vectorizer.fit_transform(X_train_text_stem)\n",
    "X_test_text_stem_vector = text_stem_vectorizer.transform(X_test_text_stem)\n",
    "X_submission_text_stem_vector = text_stem_vectorizer.transform(X_submission_text_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf text stem\n",
    "text_stem_tfidf = TfidfVectorizer()\n",
    "X_train_text_stem_tfidf = text_stem_tfidf.fit_transform(X_train_text_stem)\n",
    "X_test_text_stem_tfidf = text_stem_tfidf.transform(X_test_text_stem)\n",
    "submission_text_stem_tfidf = text_stem_tfidf.transform(X_submission_text_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countVector summary\n",
    "summary_vectorizer = CountVectorizer()\n",
    "X_train_summary_vector = summary_vectorizer.fit_transform(X_train_Summary)\n",
    "X_test_summary_vector = summary_vectorizer.transform(X_test_Summary)\n",
    "submission_summary_vector = summary_vectorizer.transform(submission_Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf summary\n",
    "summary_tfidf = TfidfVectorizer()\n",
    "X_train_summary_tfidf = summary_tfidf.fit_transform(X_train_Summary)\n",
    "X_test_summary_tfidf = summary_tfidf.transform(X_test_Summary)\n",
    "submission_summary_tfidf = summary_tfidf.transform(submission_Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countVector summary stem\n",
    "summary_stem_vectorizer = CountVectorizer()\n",
    "X_train_summary_stem_vector = summary_stem_vectorizer.fit_transform(X_train_Summary_stem)\n",
    "X_test_summary_stem_vector = summary_stem_vectorizer.transform(X_test_Summary_stem)\n",
    "X_submission_summary_stem_vector = summary_stem_vectorizer.transform(X_submission_Summary_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf text stem\n",
    "summary_stem_tfidf = TfidfVectorizer()\n",
    "X_train_summary_stem_tfidf = summary_stem_tfidf.fit_transform(X_train_Summary_stem)\n",
    "X_test_summary_stem_tfidf = summary_stem_tfidf.transform(X_test_Summary_stem)\n",
    "submission_summary_stem_tfidf = summary_stem_tfidf.transform(X_submission_Summary_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TRAINING & evaluation\n",
    "### TRAIN THE MODEL\n",
    "### https://www.ritchieng.com/machine-learning-multinomial-naive-bayes-vectorization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on text CountVector testing set =  1.2909944928498642\n"
     ]
    }
   ],
   "source": [
    "NB_text_vector = MultinomialNB()\n",
    "NB_text_vector.fit(X_train_text_vector,Y_train)\n",
    "Y_test_vector_predictions = NB_text_vector.predict(X_test_text_vector)\n",
    "print(\"RMSE on text CountVector testing set = \", mean_squared_error(Y_test, Y_test_vector_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on text TFIDF testing set =  2.209271705155654\n"
     ]
    }
   ],
   "source": [
    "NB_text_tfidf = MultinomialNB()\n",
    "NB_text_tfidf.fit(X_train_text_tfidf,Y_train)\n",
    "Y_text_tfidf_predictions = NB_text_tfidf.predict(X_test_text_vector)\n",
    "print(\"RMSE on text TFIDF testing set = \", mean_squared_error(Y_test, Y_text_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on text stem CountVector testing set =  1.322563286429054\n"
     ]
    }
   ],
   "source": [
    "NB_text_stem_vector = MultinomialNB()\n",
    "NB_text_stem_vector.fit(X_train_text_stem_vector,Y_train)\n",
    "Y_test_stem_vector_predictions = NB_text_stem_vector.predict(X_test_text_stem_vector)\n",
    "print(\"RMSE on text stem CountVector testing set = \", mean_squared_error(Y_test, Y_test_stem_vector_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on text stem TFIDF testing set =  2.210284974983112\n"
     ]
    }
   ],
   "source": [
    "NB_text_stem_tfidf = MultinomialNB()\n",
    "NB_text_stem_tfidf.fit(X_train_text_stem_tfidf,Y_train)\n",
    "Y_text_stem_tfidf_predictions = NB_text_stem_tfidf.predict(X_test_text_stem_tfidf)\n",
    "print(\"RMSE on text stem TFIDF testing set = \", mean_squared_error(Y_test, Y_text_stem_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on summary CountVector testing set =  1.3820399354255162\n"
     ]
    }
   ],
   "source": [
    "NB_summary_vector = MultinomialNB()\n",
    "NB_summary_vector.fit(X_train_summary_vector,Y_train)\n",
    "Y_summary_vector_predictions = NB_summary_vector.predict(X_test_summary_vector)\n",
    "print(\"RMSE on summary CountVector testing set = \", mean_squared_error(Y_test, Y_summary_vector_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on summary TFIDF testing set =  1.45298027272415\n"
     ]
    }
   ],
   "source": [
    "NB_summary_tfidf = MultinomialNB()\n",
    "NB_summary_tfidf.fit(X_train_summary_tfidf,Y_train)\n",
    "Y_summary_tfidf_predictions = NB_summary_tfidf.predict(X_test_summary_vector)\n",
    "print(\"RMSE on summary TFIDF testing set = \", mean_squared_error(Y_test, Y_summary_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on summary stem CountVector testing set =  1.4092808646569195\n"
     ]
    }
   ],
   "source": [
    "NB_summary_stem_vector = MultinomialNB()\n",
    "NB_summary_stem_vector.fit(X_train_summary_stem_vector,Y_train)\n",
    "Y_summary_stem_vector_predictions = NB_summary_stem_vector.predict(X_test_summary_stem_vector)\n",
    "print(\"RMSE on summary stem CountVector testing set = \", mean_squared_error(Y_test, Y_summary_stem_vector_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on summary stem TFIDF testing set =  1.6301422012571416\n"
     ]
    }
   ],
   "source": [
    "NB_summary_stem_tfidf = MultinomialNB()\n",
    "NB_summary_stem_tfidf.fit(X_train_summary_stem_tfidf,Y_train)\n",
    "Y_summary_stem_tfidf_predictions = NB_summary_stem_tfidf.predict(X_test_summary_stem_tfidf)\n",
    "print(\"RMSE on summary stem TFIDF testing set = \", mean_squared_error(Y_test, Y_summary_stem_tfidf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE SUBMISSION SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_predict = submissionSet\n",
    "# submission_predict.head()\n",
    "# submission_predict['Score'] = NB_text_vector.predict(submission_text_vector)\n",
    "# submission_output = submission_predict[['Id','Score']]\n",
    "# submission_output.to_csv(\"./data/stem&vector_submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd2e637a70a200b3ebcab9c346823b324e3cae506e7b662da0792a7bb4adc9ef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
